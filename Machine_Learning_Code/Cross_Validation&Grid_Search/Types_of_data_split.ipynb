{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1333dd36-176c-411d-967e-207bfd5908eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19a96cf6-4dab-4bcd-8120-f87f8be5f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://drive.google.com/file/d/1VD06DjyGegNAWdJxFqKW-BtNsSbZsbez/view?usp=drive_link'\n",
    "url = 'https://drive.google.com/uc?id='+ url.split('/')[-2]\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8996a784-7d2b-4e9e-b5df-b4777a669839",
   "metadata": {},
   "source": [
    "----\r\n",
    "----\r\n",
    "----\r\n",
    "## Train | Test Split Procedure \r\n",
    "\r\n",
    "0. Clean and adjust data as necessary for X and y\r\n",
    "1. Split Data in Train/Test for both X and y\r\n",
    "2. Fit/Train Scaler on Training X Data\r\n",
    "3. Scale X Test Data\r\n",
    "4. Create Model\r\n",
    "5. Fit/Train Model on X Train Data\r\n",
    "6. Evaluate Model on X Test Data (by creating predictions and comparing to Y_test)\r\n",
    "7. Adjust Parameters as Necessary and repeat steps 5 and 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58f7afe1-d243-4dc6-802c-b61c48999503",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE X and y\n",
    "X = df.drop('sales',axis=1)\n",
    "y = df['sales']\n",
    "\n",
    "# TRAIN TEST SPLIT\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# SCALE DATA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721a3917-943e-4c91-bade-57efaf9437e1",
   "metadata": {},
   "source": [
    "----\r\n",
    "----\r\n",
    "----\r\n",
    "## Train | Validation | Test Split Procedure \r\n",
    "\r\n",
    "This is often also called a \"hold-out\" set, since you should not adjust parameters based on the final test set, but instead use it *only* for reporting final expected performance.\r\n",
    "\r\n",
    "0. Clean and adjust data as necessary for X and y\r\n",
    "1. Split Data in Train/Validation/Test for both X and y\r\n",
    "2. Fit/Train Scaler on Training X Data\r\n",
    "3. Scale X Eval Data\r\n",
    "4. Create Model\r\n",
    "5. Fit/Train Model on X Train Data\r\n",
    "6. Evaluate Model on X Evaluation Data (by creating predictions and comparing to Y_eval)\r\n",
    "7. Adjust Parameters as Necessary and repeat steps 5 and 6\r\n",
    "8. Get final metrics on Test set (not allowed to go back and adjust after this!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "839fae61-94b1-43af-9aa9-e81bb09005c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE X and y\n",
    "X = df.drop('sales',axis=1)\n",
    "y = df['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efcd63c3-1c9a-40aa-8c3d-cf746e87515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "#### SPLIT TWICE! Here we create TRAIN | VALIDATION | TEST  #########\n",
    "####################################################################\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 70% of data is training data, set aside other 30%\n",
    "X_train, X_OTHER, y_train, y_OTHER = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# Remaining 30% is split into evaluation and test sets\n",
    "# Each is 15% of the original data size\n",
    "X_eval, X_test, y_eval, y_test = train_test_split(X_OTHER, y_OTHER, test_size=0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6420f4b3-ef31-4d72-8c16-e90f20bb3439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
